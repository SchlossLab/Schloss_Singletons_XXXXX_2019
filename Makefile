print-%:
	@echo '$*=$($*)'


################################################################################
#
#	Part 1: Get the reference files
#
#	Here we give instructions on how to get the necessary reference files that
#	are used throughout the rest of the analysis. These are used to calculate
#	error rates, generate alignments, and classify sequences. We will pull down
#	the mock community reference (HMP_MOCK.fasta), the silva reference alignment
#	(silva.bacteria.align), and the RDP training set data (trainset9_032012).
#
#	The targets in this part are all used as dependencies in other rules
#
################################################################################

#get the silva reference alignment
REFS = data/references/
$(REFS)silva.bacteria.align :
	wget -N -P $(REFS) http:/www.mothur.org/w/images/2/27/Silva.nr_v119.tgz; \
	tar xvzf $(REFS)Silva.nr_v119.tgz -C $(REFS);
	mothur "#get.lineage(fasta=$(REFS)silva.nr_v119.align, taxonomy=$(REFS)silva.nr_v119.tax, taxon=Bacteria)";
	mv $(REFS)silva.nr_v119.pick.align $(REFS)silva.bacteria.align; \
	rm $(REFS)README.html; \
	rm $(REFS)README.Rmd; \
	rm $(REFS)silva.nr_v119.*

$(REFS)silva.v4.align : $(REFS)silva.bacteria.align
	mothur "#pcr.seqs(fasta=$^, start=11894, end=25319, keepdots=F, processors=8);degap.seqs();unique.seqs()"
	cut -f 1 $(REFS)silva.bacteria.pcr.ng.names > $(REFS)silva.bacteria.pcr.ng.accnos
	mothur "#get.seqs(fasta=$(REFS)silva.bacteria.pcr.align, accnos=$(REFS)silva.bacteria.pcr.ng.accnos);screen.seqs(minlength=240, maxlength=275, maxambig=0, maxhomop=8, processors=8); filter.seqs(vertical=T)"
	rm $(REFS)silva.bacteria.pcr.align
	rm $(REFS)silva.bacteria.pcr.ng.fasta
	rm $(REFS)silva.bacteria.pcr.ng.names
	rm $(REFS)silva.bacteria.pcr.ng.unique.fasta
	rm $(REFS)silva.bacteria.pcr.ng.accnos
	rm $(REFS)silva.bacteria.pcr.pick.good.align
	rm $(REFS)silva.bacteria.pcr.pick.bad.accnos
	rm $(REFS)silva.filter
	mv $(REFS)silva.bacteria.pcr.pick.good.filter.fasta $@

#get the rdp training set data
$(REFS)trainset10_082014.pds.tax $(REFS)trainset10_082014.pds.fasta :
	wget -N -P $(REFS) http:/www.mothur.org/w/images/2/24/Trainset10_082014.pds.tgz; \
	tar xvzf $(REFS)Trainset10_082014.pds.tgz -C $(REFS);\
	mv $(REFS)trainset10_082014.pds/trainset10_082014.* $(REFS);\
	rm -rf $(REFS)trainset10_082014.pds

#get the mock community reference sequences
$(REFS)HMP_MOCK.fasta :
	wget -N -P $(REFS) http://www.mothur.org/MiSeqDevelopmentData/HMP_MOCK.fasta



################################################################################
#
#	Part 2: Get the raw sequence data from Kozich et al and process
#
#	Here we will pull down the fastq files generated by the sequencer that are
#	stored on our public server. We will store these data in the data/raw/RUNS
# folders. We will alter the deltaQ value (0 and 6) and will run the four
# libraries through a common pipeline keeping the chimera-checked fasta and
# count files and then clustering the data to generate a shared file.
#
#	The output we want from this section includes the error rates for the Mock
# community data and shared file for each library type.
#
################################################################################

# Download all of the fastq files from Kozich et al. For now we'll just take the
# last run, but we'll build this out so that we just add something to RUNS to
# get the other datasets.
RUNS = 130422

# The 24 fastq files that come with each run. They were compressed with bz2
# but to save room we'll switch them to gz
FASTQS = Mock1_S1_L001_R1_001.fastq.gz Mock2_S2_L001_R1_001.fastq.gz \
	Mock3_S3_L001_R1_001.fastq.gz Human1_S7_L001_R1_001.fastq.gz \
	Human2_S8_L001_R1_001.fastq.gz Human3_S9_L001_R1_001.fastq.gz \
	Mouse1_S10_L001_R1_001.fastq.gz Mouse2_S11_L001_R1_001.fastq.gz \
	Mouse3_S12_L001_R1_001.fastq.gz Soil1_S4_L001_R1_001.fastq.gz \
	Soil2_S5_L001_R1_001.fastq.gz Soil3_S6_L001_R1_001.fastq.gz \
	Mock1_S1_L001_R2_001.fastq.gz Mock2_S2_L001_R2_001.fastq.gz \
	Mock3_S3_L001_R2_001.fastq.gz Human1_S7_L001_R2_001.fastq.gz \
	Human2_S8_L001_R2_001.fastq.gz Human3_S9_L001_R2_001.fastq.gz \
	Mouse1_S10_L001_R2_001.fastq.gz Mouse2_S11_L001_R2_001.fastq.gz \
	Mouse3_S12_L001_R2_001.fastq.gz Soil1_S4_L001_R2_001.fastq.gz \
	Soil2_S5_L001_R2_001.fastq.gz Soil3_S6_L001_R2_001.fastq.gz

# Location of raw runs' data on local machine
RAW_RUNSPATH = $(addprefix data/raw/,$(RUNS))

# Location of processed runs' data on local machine
PROC_RUNSPATH = $(addprefix data/process/,$(RUNS))

ALL_FASTQ = $(foreach R,$(RAW_RUNSPATH),$(foreach F,$(FASTQS),$(R)/$(F)))

$(ALL_FASTQ) :
	wget -N -P $(dir $@) http://www.mothur.org/MiSeqDevelopmentData/$(patsubst data/raw/%/,%,$(dir $@)).tar
	tar xvf $(dir $@)*.tar -C $(dir $@);
	bunzip2 -f $(dir $@)*bz2;
	gzip -f $(dir $@)*fastq
	rm $(dir $@)*.tar


SAMPLES = mock human mouse soil
FILES_FILES = $(foreach S,$(SAMPLES),data/references/$(S).files)

DELTAQ = 1 6
KOZICH_FASTA = $(foreach S,$(SAMPLES),$(foreach Q,$(DELTAQ),$(PROC_RUNSPATH)/$(S)_$(Q).fasta))
KOZICH_COUNT = $(subst fasta,count_table,$(KOZICH_FASTA))
KOZICH_TAXONOMY = $(subst fasta,taxonomy,$(KOZICH_FASTA))
KOZICH_SHARED = $(subst fasta,shared,$(KOZICH_FASTA))
KOZICH_ERROR = $(foreach Q,$(DELTAQ),$(PROC_RUNSPATH)/mock_$(Q).error_summary)


$(KOZICH_FASTA) $(KOZICH_COUNT) $(KOZICH_TAXONOMY) : $(ALL_FASTQ) $(FILES_FILES) code/bash/run_mothur_to_remove_lineage.sh
	$(eval PARSE=$(subst _, ,$(basename $(notdir $@))))
	$(eval S=$(word 1,$(PARSE)))
	$(eval DQ=$(word 2,$(PARSE)))
	$(eval R=$(patsubst data/process/%/,%,$(dir $@)))
	bash code/bash/run_mothur_to_remove_lineage.sh $(R) $(S) $(DQ)

.SECONDEXPANSION:
$(KOZICH_SHARED) : $$(subst shared,fasta,$$@) $$(subst shared,count_table,$$@) $$(subst shared,taxonomy,$$@) code/bash/run_mothur_to_shared.sh
	$(eval FASTA=$(word 1, $^))
	$(eval COUNT=$(word 2, $^))
	$(eval TAXONOMY=$(word 3, $^))
	bash code/bash/run_mothur_to_shared.sh $(FASTA) $(COUNT) $(TAXONOMY)

#Add error analysis here...
$(KOZICH_ERROR) : $$(subst error_summary,fasta,$$@) $$(subst error_summary,count_table,$$@) $(REFS)HMP_MOCK.fasta code/bash/run_mothur_error_summary.sh
	$(eval FASTA=$(word 1, $^))
	$(eval COUNT=$(word 2, $^))
	$(eval HMP=$(word 3, $^))
	bash code/bash/run_mothur_error_summary.sh $(FASTA) $(COUNT) $(HMP)


################################################################################
#
#	Part 3: Get the process shared files from Kozich et al (mouse_time) and Baxter
# et al. (crc)
#
#	Here we will pull down the shared files used in these projects to get an idea
# of the distribution of sequence reads across samples.
#
################################################################################

# Download Baxter et al's CRC shared file...
data/raw/crc.shared :
	wget --no-check-certificate https://github.com/SchlossLab/Baxter_glne007Modeling_2015/blob/master/data/glne007.final.an.unique_list.shared?raw=true -O $@


# Download Kozich et al's mouse_time shared file...
data/raw/mouse_time.shared :
	wget --no-check-certificate https://github.com/SchlossLab/Kozich_MiSeqSOP_AEM_2013/blob/master/data/process/no_metag/no_metag.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.shared?raw=true -O $@
